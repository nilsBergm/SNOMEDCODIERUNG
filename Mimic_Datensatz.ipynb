{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nilsBergm/SNOMEDCODIERUNG/blob/main/Mimic_Datensatz.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCNWzLSQVTHT"
      },
      "source": [
        "Aus dem Mimic-IV-ED Datensatz die Patientenaufenthalte nur die wichtigsten Informationen behalten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q82cu-gR9NSI",
        "outputId": "7f682c3b-0ed5-4ad1-9e5e-9ed64ea92837"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Die gefilterte Datei wurde erfolgreich gespeichert: /content/drive/MyDrive/MIMIC-IV-ED/filtered_edstays.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Pfad zur ursprünglichen CSV-Datei\n",
        "file_path = '/content/drive/MyDrive/MIMIC-IV-ED/edstays.csv/edstays.csv'\n",
        "\n",
        "# Lade die CSV-Datei\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Behalte nur die gewünschten Spalten\n",
        "filtered_df = df[['subject_id', 'stay_id', 'gender', 'race', 'arrival_transport', 'disposition']]\n",
        "\n",
        "# Speichere das Ergebnis als neue CSV-Datei\n",
        "output_path = '/content/drive/MyDrive/MIMIC-IV-ED/filtered_edstays.csv'\n",
        "filtered_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Die gefilterte Datei wurde erfolgreich gespeichert: {output_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRpwKzwgV3oS"
      },
      "source": [
        "Die gefilterten Patientenaufenthalte werden mit den entsprechenden Diagnosen verbunden. Pro Patientenaufenthalt kann es mehrere Diagnosen geben"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVYnQcI2fGia"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Lade die erste CSV-Datei\n",
        "df1 = pd.read_csv('/content/drive/MyDrive/MIMIC-IV-ED/filtered_edstays.csv')\n",
        "\n",
        "# Lade die zweite CSV-Datei (nur zur Ermittlung der Größe)\n",
        "df2 = pd.read_csv('/content/drive/MyDrive/MIMIC-IV-ED/diagnosis.csv/diagnosis.csv')\n",
        "\n",
        "# Ermittle die Anzahl der Teile, in die df2 aufgeteilt werden soll\n",
        "num_parts = 100\n",
        "\n",
        "# Teile df2 in etwa gleich große Teile auf\n",
        "part_size = np.ceil(len(df2) / num_parts)\n",
        "\n",
        "# Initialisiere das Ergebnis-DataFrame\n",
        "result_df = pd.DataFrame()\n",
        "\n",
        "for part in range(num_parts):\n",
        "    # Lade den entsprechenden Teil von df2\n",
        "    start_row = int(part * part_size)\n",
        "    end_row = int(start_row + part_size)\n",
        "    df2_part = df2.iloc[start_row:end_row]\n",
        "\n",
        "    # Aggregiere die Daten in df2_part\n",
        "    aggregated_df2_part = df2_part.groupby(['subject_id', 'stay_id']).agg({\n",
        "        'seq_num': lambda x: list(x),\n",
        "        'icd_code': lambda x: '|'.join(x.astype(str)),\n",
        "        'icd_version': 'first',  # Angenommen, die icd_version ist innerhalb einer Gruppe gleich\n",
        "        'icd_title': lambda x: '|'.join(x.astype(str))\n",
        "    }).reset_index()\n",
        "\n",
        "    # Führe den aggregierten Teil mit df1 zusammen\n",
        "    merged_part = pd.merge(df1, aggregated_df2_part, on=['subject_id', 'stay_id'], how='left')\n",
        "\n",
        "    # Füge das Ergebnis zum resultierenden DataFrame hinzu\n",
        "    result_df = pd.concat([result_df, merged_part], axis=0)\n",
        "\n",
        "# Entferne Duplikate, falls nötig\n",
        "result_df = result_df.drop_duplicates(subset=['subject_id', 'stay_id']).reset_index(drop=True)\n",
        "\n",
        "# Speichere das Ergebnis als neue CSV-Datei\n",
        "result_df.to_csv('/content/drive/MyDrive/MIMIC-IV-ED/filtered_edstays_diagnosis_aggregated_chunked.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tySUY7i1WBDg"
      },
      "source": [
        "Überprüfen, dass kein Patientenaufenthalt verloren geht"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XidzvFTBoVrd",
        "outputId": "0bba8f6b-ad0a-4d6e-969d-f48c62fc4edb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-3-2c0db4fe40da>:4: DtypeWarning: Columns (6,7,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df1 = pd.read_csv('/content/drive/MyDrive/MIMIC-IV-ED/filtered_edstays_diagnosis_aggregated_chunked.csv')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Anzahl der Zeilen: 425087\n",
            "Anzahl der Zeilen: 425087\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Lade die CSV-Datei\n",
        "df1 = pd.read_csv('/content/drive/MyDrive/MIMIC-IV-ED/filtered_edstays_diagnosis_aggregated_chunked.csv')\n",
        "df2 = pd.read_csv('/content/drive/MyDrive/MIMIC-IV-ED/filtered_edstays.csv')\n",
        "\n",
        "# Ermittle die Anzahl der Zeilen\n",
        "anzahl_zeilen1 = len(df1)\n",
        "anzahl_zeilen2 = len(df2)\n",
        "\n",
        "print(f\"Anzahl der Zeilen: {anzahl_zeilen1}\")\n",
        "print(f\"Anzahl der Zeilen: {anzahl_zeilen2}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMJU18fhWSHP"
      },
      "source": [
        "Den bisherigen Datensatz mit den Triage Werte verbinden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LICTNDQp5h8",
        "outputId": "cea2872d-1fc4-4883-d0d2-341d44c1e320"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-4-9af999723435>:4: DtypeWarning: Columns (6,7,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df1 = pd.read_csv('/content/drive/MyDrive/MIMIC-IV-ED/filtered_edstays_diagnosis_aggregated_chunked.csv')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Lade die erste CSV-Datei\n",
        "df1 = pd.read_csv('/content/drive/MyDrive/MIMIC-IV-ED/filtered_edstays_diagnosis_aggregated_chunked.csv')\n",
        "\n",
        "# Lade die zweite CSV-Datei\n",
        "df2 = pd.read_csv('/content/drive/MyDrive/MIMIC-IV-ED/triage.csv/triage.csv')\n",
        "\n",
        "# Führe die Dateien anhand von 'subject_id' und 'stay_id' zusammen\n",
        "merged_df = pd.merge(df1, df2, on=['subject_id', 'stay_id'], how='inner')\n",
        "\n",
        "# Speichere das Ergebnis als neue CSV-Datei\n",
        "merged_df.to_csv('/content/drive/MyDrive/MIMIC-IV-ED/filtered_edstays_diagnosis_triage.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDudKN4qWe2M"
      },
      "source": [
        "Die bisherigen Daten um Medikamente erweitern, pro Patientenaufenthalt gibt es wieder mehrere Medikamente, daher muss dafür gesorgt werden, dass alle Medikamente dem richtigen Patientenfall zugeordnet ist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ONoNHPOWOni",
        "outputId": "68352aca-63cb-4d91-d1d5-8b8596fd37cb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-6-84cab7a4fc86>:4: DtypeWarning: Columns (6,7,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df1 = pd.read_csv('/content/drive/MyDrive/MIMIC-IV-ED/filtered_edstays_diagnosis_triage.csv')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Lade die erste und zweite CSV-Datei\n",
        "df1 = pd.read_csv('/content/drive/MyDrive/MIMIC-IV-ED/filtered_edstays_diagnosis_triage.csv')\n",
        "df2 = pd.read_csv('/content/drive/MyDrive/MIMIC-IV-ED/medrecon.csv/medrecon.csv')\n",
        "\n",
        "# Aggregiere 'name' und 'gsn' in der zweiten Datei, getrennt durch ein Semikolon\n",
        "df2_aggregated = df2.groupby(['subject_id', 'stay_id']).agg({\n",
        "    'name': lambda x: '; '.join(x.astype(str)),\n",
        "    'gsn': lambda x: '; '.join(x.astype(str))\n",
        "}).reset_index()\n",
        "\n",
        "# Benenne die Spalten um\n",
        "df2_aggregated.rename(columns={'name': 'name_medrecon', 'gsn': 'gsn_medrecon'}, inplace=True)\n",
        "\n",
        "# Führe einen linksseitigen Join der beiden DataFrames durch\n",
        "merged_df = pd.merge(df1, df2_aggregated, on=['subject_id', 'stay_id'], how='left')\n",
        "\n",
        "# Speichere das Ergebnis als neue CSV-Datei\n",
        "merged_df.to_csv('/content/drive/MyDrive/MIMIC-IV-ED/filtered_edstays_diagnosis_triage_medrecon.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hTV866pWyZN"
      },
      "source": [
        "Genau das gleiche mit den Medikamenten während des Aufenthalts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwYvJPANYb0J",
        "outputId": "89710184-3677-474d-af64-c3d4aa75a057"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-89579c8e508e>:4: DtypeWarning: Columns (6,7,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df1 = pd.read_csv('/content/drive/MyDrive/MIMIC-IV-ED/filtered_edstays_diagnosis_triage_medrecon.csv')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Lade die erste und zweite CSV-Datei\n",
        "df1 = pd.read_csv('/content/drive/MyDrive/MIMIC-IV-ED/filtered_edstays_diagnosis_triage_medrecon.csv')\n",
        "df2 = pd.read_csv('/content/drive/MyDrive/MIMIC-IV-ED/pyxis.csv/pyxis.csv')\n",
        "\n",
        "# Aggregiere 'name' und 'gsn' in der zweiten Datei, getrennt durch ein Semikolon\n",
        "df2_aggregated = df2.groupby(['subject_id', 'stay_id']).agg({\n",
        "    'name': lambda x: '; '.join(x.astype(str)),\n",
        "    'gsn': lambda x: '; '.join(x.astype(str))\n",
        "}).reset_index()\n",
        "\n",
        "# Benenne die Spalten um\n",
        "df2_aggregated.rename(columns={'name': 'name_pyxis', 'gsn': 'gsn_pyxis'}, inplace=True)\n",
        "\n",
        "# Führe einen linksseitigen Join der beiden DataFrames durch\n",
        "merged_df = pd.merge(df1, df2_aggregated, on=['subject_id', 'stay_id'], how='left')\n",
        "\n",
        "# Speichere das Ergebnis als neue CSV-Datei\n",
        "merged_df.to_csv('/content/drive/MyDrive/MIMIC-IV-ED/filtered_edstays_diagnosis_triage_medrecon_pyxis.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvKZTDv7W4Dk"
      },
      "source": [
        "Kleineren Datensatz erstellen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjEX1E_3i_5e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Lese die ersten 50 Zeilen der CSV-Datei\n",
        "df = pd.read_csv('/content/drive/MyDrive/MIMIC-IV-ED/filtered_edstays_diagnosis_triage_medrecon_pyxis.csv', nrows=50)\n",
        "\n",
        "# Speichere diese 50 Zeilen in eine neue CSV-Datei\n",
        "df.to_csv('/content/drive/MyDrive/MIMIC-IV-ED/filtered_edstays_diagnosis_triage_medrecon_pyxis_firstrows.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Codierung:"
      ],
      "metadata": {
        "id": "20rwEDnwdwsA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests-html\n",
        "!pip install wheel\n",
        "!pip install --upgrade pip\n",
        "!pip install --upgrade build"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SH0LIQYCeCoo",
        "outputId": "505d67c7-afb3-4fb8-ff5d-6941c884ea87"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting requests-html\n",
            "  Downloading requests_html-0.10.0-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from requests-html) (2.31.0)\n",
            "Collecting pyquery (from requests-html)\n",
            "  Downloading pyquery-2.0.0-py3-none-any.whl (22 kB)\n",
            "Collecting fake-useragent (from requests-html)\n",
            "  Downloading fake_useragent-1.5.1-py3-none-any.whl (17 kB)\n",
            "Collecting parse (from requests-html)\n",
            "  Downloading parse-1.20.1-py2.py3-none-any.whl (20 kB)\n",
            "Collecting bs4 (from requests-html)\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Collecting w3lib (from requests-html)\n",
            "  Downloading w3lib-2.1.2-py3-none-any.whl (21 kB)\n",
            "Collecting pyppeteer>=0.0.14 (from requests-html)\n",
            "  Downloading pyppeteer-2.0.0-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.9/82.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: appdirs<2.0.0,>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests-html) (1.4.4)\n",
            "Requirement already satisfied: certifi>=2023 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests-html) (2024.2.2)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests-html) (7.0.2)\n",
            "Collecting pyee<12.0.0,>=11.0.0 (from pyppeteer>=0.0.14->requests-html)\n",
            "  Downloading pyee-11.1.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests-html) (4.66.2)\n",
            "Collecting urllib3<2.0.0,>=1.25.8 (from pyppeteer>=0.0.14->requests-html)\n",
            "  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets<11.0,>=10.0 (from pyppeteer>=0.0.14->requests-html)\n",
            "  Downloading websockets-10.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4->requests-html) (4.12.3)\n",
            "Requirement already satisfied: lxml>=2.1 in /usr/local/lib/python3.10/dist-packages (from pyquery->requests-html) (4.9.4)\n",
            "Collecting cssselect>=1.2.0 (from pyquery->requests-html)\n",
            "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->requests-html) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->requests-html) (3.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html) (3.18.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pyee<12.0.0,>=11.0.0->pyppeteer>=0.0.14->requests-html) (4.10.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4->requests-html) (2.5)\n",
            "Installing collected packages: parse, fake-useragent, websockets, w3lib, urllib3, pyee, cssselect, pyquery, pyppeteer, bs4, requests-html\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "Successfully installed bs4-0.0.2 cssselect-1.2.0 fake-useragent-1.5.1 parse-1.20.1 pyee-11.1.0 pyppeteer-2.0.0 pyquery-2.0.0 requests-html-0.10.0 urllib3-1.26.18 w3lib-2.1.2 websockets-10.4\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (0.43.0)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-24.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "Successfully installed pip-24.0\n",
            "Requirement already satisfied: build in /usr/local/lib/python3.10/dist-packages (1.1.1)\n",
            "Requirement already satisfied: packaging>=19.0 in /usr/local/lib/python3.10/dist-packages (from build) (24.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build) (1.0.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build) (2.0.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/lhncbc/skr_web_python_api.git\n",
        "%cd skr_web_python_api/\n",
        "!python3 -m build"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eC8hdOreeFHO",
        "outputId": "91d0590b-428c-4a46-cc68-42cacc603837"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'skr_web_python_api'...\n",
            "remote: Enumerating objects: 59, done.\u001b[K\n",
            "remote: Counting objects: 100% (59/59), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 59 (delta 29), reused 53 (delta 23), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (59/59), 14.55 KiB | 7.27 MiB/s, done.\n",
            "Resolving deltas: 100% (29/29), done.\n",
            "/content/skr_web_python_api\n",
            "\u001b[1m* Creating venv isolated environment...\u001b[0m\n",
            "\u001b[1m* Installing packages in isolated environment... (setuptools>=42)\u001b[0m\n",
            "\u001b[1m* Getting build dependencies for sdist...\u001b[0m\n",
            "running egg_info\n",
            "creating src/skr_web_api.egg-info\n",
            "writing src/skr_web_api.egg-info/PKG-INFO\n",
            "writing dependency_links to src/skr_web_api.egg-info/dependency_links.txt\n",
            "writing top-level names to src/skr_web_api.egg-info/top_level.txt\n",
            "writing manifest file 'src/skr_web_api.egg-info/SOURCES.txt'\n",
            "reading manifest file 'src/skr_web_api.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'src/skr_web_api.egg-info/SOURCES.txt'\n",
            "\u001b[1m* Building sdist...\u001b[0m\n",
            "running sdist\n",
            "running egg_info\n",
            "writing src/skr_web_api.egg-info/PKG-INFO\n",
            "writing dependency_links to src/skr_web_api.egg-info/dependency_links.txt\n",
            "writing top-level names to src/skr_web_api.egg-info/top_level.txt\n",
            "reading manifest file 'src/skr_web_api.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'src/skr_web_api.egg-info/SOURCES.txt'\n",
            "running check\n",
            "creating skr_web_api-0.1\n",
            "creating skr_web_api-0.1/src\n",
            "creating skr_web_api-0.1/src/skr_web_api\n",
            "creating skr_web_api-0.1/src/skr_web_api.egg-info\n",
            "copying files to skr_web_api-0.1...\n",
            "copying LICENSE -> skr_web_api-0.1\n",
            "copying README.md -> skr_web_api-0.1\n",
            "copying pyproject.toml -> skr_web_api-0.1\n",
            "copying setup.cfg -> skr_web_api-0.1\n",
            "copying src/skr_web_api/__init__.py -> skr_web_api-0.1/src/skr_web_api\n",
            "copying src/skr_web_api/casauth.py -> skr_web_api-0.1/src/skr_web_api\n",
            "copying src/skr_web_api.egg-info/PKG-INFO -> skr_web_api-0.1/src/skr_web_api.egg-info\n",
            "copying src/skr_web_api.egg-info/SOURCES.txt -> skr_web_api-0.1/src/skr_web_api.egg-info\n",
            "copying src/skr_web_api.egg-info/dependency_links.txt -> skr_web_api-0.1/src/skr_web_api.egg-info\n",
            "copying src/skr_web_api.egg-info/top_level.txt -> skr_web_api-0.1/src/skr_web_api.egg-info\n",
            "copying src/skr_web_api.egg-info/SOURCES.txt -> skr_web_api-0.1/src/skr_web_api.egg-info\n",
            "Writing skr_web_api-0.1/setup.cfg\n",
            "Creating tar archive\n",
            "removing 'skr_web_api-0.1' (and everything under it)\n",
            "\u001b[1m* Building wheel from sdist\u001b[0m\n",
            "\u001b[1m* Creating venv isolated environment...\u001b[0m\n",
            "\u001b[1m* Installing packages in isolated environment... (setuptools>=42)\u001b[0m\n",
            "\u001b[1m* Getting build dependencies for wheel...\u001b[0m\n",
            "running egg_info\n",
            "writing src/skr_web_api.egg-info/PKG-INFO\n",
            "writing dependency_links to src/skr_web_api.egg-info/dependency_links.txt\n",
            "writing top-level names to src/skr_web_api.egg-info/top_level.txt\n",
            "reading manifest file 'src/skr_web_api.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'src/skr_web_api.egg-info/SOURCES.txt'\n",
            "\u001b[1m* Installing packages in isolated environment... (wheel)\u001b[0m\n",
            "\u001b[1m* Building wheel...\u001b[0m\n",
            "running bdist_wheel\n",
            "running build\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/skr_web_api\n",
            "copying src/skr_web_api/__init__.py -> build/lib/skr_web_api\n",
            "copying src/skr_web_api/casauth.py -> build/lib/skr_web_api\n",
            "installing to build/bdist.linux-x86_64/wheel\n",
            "running install\n",
            "running install_lib\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/wheel\n",
            "creating build/bdist.linux-x86_64/wheel/skr_web_api\n",
            "copying build/lib/skr_web_api/__init__.py -> build/bdist.linux-x86_64/wheel/skr_web_api\n",
            "copying build/lib/skr_web_api/casauth.py -> build/bdist.linux-x86_64/wheel/skr_web_api\n",
            "running install_egg_info\n",
            "running egg_info\n",
            "writing src/skr_web_api.egg-info/PKG-INFO\n",
            "writing dependency_links to src/skr_web_api.egg-info/dependency_links.txt\n",
            "writing top-level names to src/skr_web_api.egg-info/top_level.txt\n",
            "reading manifest file 'src/skr_web_api.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'src/skr_web_api.egg-info/SOURCES.txt'\n",
            "Copying src/skr_web_api.egg-info to build/bdist.linux-x86_64/wheel/skr_web_api-0.1-py3.10.egg-info\n",
            "running install_scripts\n",
            "creating build/bdist.linux-x86_64/wheel/skr_web_api-0.1.dist-info/WHEEL\n",
            "creating '/content/skr_web_python_api/dist/.tmp-pwvl3z56/skr_web_api-0.1-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
            "adding 'skr_web_api/__init__.py'\n",
            "adding 'skr_web_api/casauth.py'\n",
            "adding 'skr_web_api-0.1.dist-info/LICENSE'\n",
            "adding 'skr_web_api-0.1.dist-info/METADATA'\n",
            "adding 'skr_web_api-0.1.dist-info/WHEEL'\n",
            "adding 'skr_web_api-0.1.dist-info/top_level.txt'\n",
            "adding 'skr_web_api-0.1.dist-info/RECORD'\n",
            "removing build/bdist.linux-x86_64/wheel\n",
            "\u001b[1m\u001b[92mSuccessfully built \u001b[4mskr_web_api-0.1.tar.gz\u001b[0m\u001b[1m\u001b[92m and \u001b[4mskr_web_api-0.1-py3-none-any.whl\u001b[0m\u001b[1m\u001b[92m\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dist/skr_web_api-0.1-py3-none-any.whl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZpmCCU4eIBn",
        "outputId": "5b717e66-29c7-4695-c351-3e5d9e6df320"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ./dist/skr_web_api-0.1-py3-none-any.whl\n",
            "Installing collected packages: skr-web-api\n",
            "Successfully installed skr-web-api-0.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from skr_web_api import Submission\n",
        "import requests\n",
        "import re\n",
        "\n",
        "# Pfad zur CSV-Datei\n",
        "file_path = '/content/drive/MyDrive/MIMIC-IV-ED/filtered_age_edstays_diagnosis_triage_medrecon_pyxis.csv'\n",
        "\n",
        "# Lese die gesamte CSV-Datei\n",
        "df_full = pd.read_csv(file_path)\n",
        "\n",
        "# Überprüfe, ob die Datei mindestens 100 Zeilen hat\n",
        "if len(df_full) >= 100:\n",
        "    # Wähle zufällig 100 Zeilen aus\n",
        "    df_sampled = df_full.sample(n=100, random_state=1)  # `random_state` sorgt für Reproduzierbarkeit\n",
        "else:\n",
        "    print(\"Die Datei enthält weniger als 100 Zeilen.\")\n",
        "    df_sampled = df_full\n",
        "\n",
        "# Speichere die 100 zufällig ausgewählten Zeilen in eine neue CSV-Datei\n",
        "#df_sampled.to_csv('/content/drive/MyDrive/MIMIC-IV-ED/filtered_age_edstays_diagnosis_triage_medrecon_pyxis_firstrow.csv', index=False)\n",
        "# Lese die ersten 10 Zeilen der CSV-Datei\n",
        "df = pd.read_csv('/content/drive/MyDrive/MIMIC-IV-ED/filtered_age_edstays_diagnosis_triage_medrecon_pyxis.csv', nrows=1000)\n",
        "\n",
        "# Speichere diese 10 Zeilen in eine neue CSV-Datei\n",
        "df.to_csv('/content/drive/MyDrive/MIMIC-IV-ED/filtered_age_edstays_diagnosis_triage_medrecon_pyxis_firstrow.csv', index=False)\n",
        "\n",
        "email = 'nilsbergmann.ab@gmail.com'\n",
        "api_key = 'your_key'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "abbreviations = {\n",
        "    r\"\\bl\\b\": \"left\",\n",
        "    r\"\\br\\b\": \"right\",\n",
        "    r\"\\bs/p\\b\": \"status post\",\n",
        "    r\"\\bb\\b\": \"bilateral\",\n",
        "    r\"\\babnormal labs\\b\": \"Laboratory test result abnormal\",\n",
        "    r\"\\blabs abnormal\\b\": \"Laboratory test result abnormal\",\n",
        "    r\"\\babd\\b\": \"abdominal\",\n",
        "    r\"\\bn/v/d\\b\": \"nausea, vomiting, diarrhea\",\n",
        "    r\"\\bn/v\\b\": \"nausea, vomiting\",\n",
        "    r\"\\bCB/SOB\\b\": \"Cough and Shortness of Breath\",\n",
        "    r\"\\bCP/SOB\\b\": \"Chest Pain and Shortness of Breath\", #Sollte eher als 2 Begriffe genommen werden!!!!\n",
        "    r\"\\bLE\\b\": \"Lower Extremity\",\n",
        "    r\"\\bNOS\\b\": \"Not Otherwise Specified\",\n",
        "    r\"\\bFB\\b\": \"Foreign Body\",\n",
        "    r\"\\bOTH SEQUELA\\b\": \"Other Sequelae\",\n",
        "    r\"\\bCHR LIV DIS\\b\": \"Chronic Liver Disease\",\n",
        "    r\"\\bABDOMINAL PAIN UNSPEC SITE\\b\": \"Abdominal Pain, Unspecified Site\",\n",
        "    r\"\\bw\\b\": \"with\",\n",
        "    r\"\\bw/o\\b\": \"without\",\n",
        "    r\"\\(\": \"\",\n",
        "    r\"\\)\": \"\",\n",
        "    r\"\\bCELLULITIS/ABSCESS MOUTH\\b\": \"Cellulitis/Abscess of the Mouth\",\n",
        "    r\"\\bLOCAL SUPRFICIAL SWELLNG\\b\": \"Local Superficial Swelling\",\n",
        "    r\"\\bCONG FACTOR VIII DIORD\\b\": \"Congenital Factor VIII Disorder\",\n",
        "    r\"\\bLIVER DISORDERS NEC\\b\": \"Liver Disorders, Not Elsewhere Classified\",\n",
        "    r\"\\bMAL NEO BRONCH/LUNG Not Otherwise Specified\\b\": \"Malignant Neoplasm of Bronchus/Lung, Not Otherwise Specified\",\n",
        "    r\"\\bHX-BRONCHOGENIC MALIGNAN\\b\": \"History of Bronchogenic Malignancy\",\n",
        "    r\"\\bNASAL BONE FX-CLOSED\\b\": \"Nasal Bone Fracture, Closed\",\n",
        "    r\"\\bTETANUS-DIPHT. TD DT\\b\": \"Tetanus-Diphtheria (Vaccines)\",\n",
        "    r\"\\bDIABETES UNCOMPL ADULT\\b\": \"Diabetes, Uncomplicated, Adult\",\n",
        "    r\"\\bLONG TERM USE ANTIGOAGULANT\\b\": \"Long-term Use of Anticoagulants\",\n",
        "    r\"\\bINTERMED CORONARY SYND\\b\": \"Intermediate Coronary Syndrome\",\n",
        "    r\"\\bRESPIRATORY ABNORM NEC\\b\": \"Respiratory Abnormalities, Not Elsewhere Classified\",\n",
        "    r\"\\bCAD UNSPEC VESSEL, NATIVE OR GRAFT\\b\": \"Coronary Artery Disease, Unspecified Vessel, Native or Graft\",\n",
        "    r\"\\bDIABETES UNCOMPL JUVEN\\b\": \"Diabetes, Uncomplicated, Juvenile\",\n",
        "    r\"\\bURIN TRACT INFECTION Not Otherwise Specified\\b\": \"Urinary Tract Infection, Not Otherwise Specified\",\n",
        "    r\"\\bFX RADIUS HEAD-CLOSED\\b\": \"Fracture of Radius Head, Closed\",\n",
        "    r\"\\bUNSPEC VIRAL INFECTION\\b\": \"Unspecified Viral Infection\",\n",
        "    r\"\\bRENAL & URETERAL DIS Not Otherwise Specified\\b\": \"Renal and Ureteral Disorder, Not Otherwise Specified\",\n",
        "    r\"\\bMYOCARDIAL INFARCTION Not Otherwise Specified, INIT EPISODE OF CARE\\b\": \"Myocardial Infarction, Not Otherwise Specified, Initial Episode of Care\",\n",
        "    r\"\\bChronic obstructive pulmonary disease with acute exacerbation\\b\": \"Chronic obstructive pulmonary disease exacerbation\"\n",
        "}\n",
        "\n",
        "def replace_abbreviations(inputtext):\n",
        "    for abbr, replacement in abbreviations.items():\n",
        "        # Das Muster erkennt die Abkürzung, wenn sie von Wortgrenzen (\\b) umgeben ist,\n",
        "        # was bedeutet, dass sie nur als eigenständiges Wort ersetzt wird.\n",
        "        # Die Verwendung von re.IGNORECASE ermöglicht es, Groß-/Kleinschreibung zu ignorieren.\n",
        "        inputtext = re.sub(abbr, replacement, inputtext, flags=re.IGNORECASE)\n",
        "    return inputtext\n",
        "\n",
        "\n",
        "def get_snomed_ct_codes_from_cui(cui, api_key, inputtext_for_error):\n",
        "    base_url = f\"https://uts-ws.nlm.nih.gov/rest/content/current/CUI/{cui}/atoms\"\n",
        "    params = {\n",
        "        \"apiKey\": api_key,\n",
        "        \"language\": \"ENG\",\n",
        "        \"pageNumber\": 1,\n",
        "        \"sabs\": \"SNOMEDCT_US\"\n",
        "    }\n",
        "\n",
        "    response = requests.get(base_url, params=params)\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "\n",
        "        prioritized_results = {'FN': [], 'PT': [], 'SY': []}\n",
        "        other_terms = []  # Liste für Codes anderer termTypes\n",
        "\n",
        "        # Durchlaufe die Atome und ordne sie nach termType\n",
        "        for atom in data['result']:\n",
        "            term_type = atom.get('termType')\n",
        "            code = atom['code'].split('/')[-1]  # Extrahiere den SNOMED CT Code aus der URL\n",
        "            if term_type in prioritized_results:\n",
        "                prioritized_results[term_type].append((code, atom['name']))\n",
        "            else:\n",
        "                other_terms.append((code, atom['name']))  # Füge andere termTypes zu einer separaten Liste hinzu\n",
        "\n",
        "        # Wähle den am höchsten priorisierten Term-Typ aus, der verfügbar ist\n",
        "        for term_type in ['FN', 'PT', 'SY']:\n",
        "            if prioritized_results[term_type]:\n",
        "                return prioritized_results[term_type]\n",
        "\n",
        "        if other_terms:  # Wenn keine bevorzugten termTypes vorhanden sind, gib einen anderen zurück\n",
        "            return other_terms\n",
        "    else:\n",
        "        #print(f\"Error while processing input text '{inputtext_for_error}'. Received status code {response.status_code}\")\n",
        "        #if response.content:\n",
        "            #print(\"Response content:\", response.content.decode('utf-8'))\n",
        "        return []  # Gib eine leere Liste zurück, wenn keine Daten gefunden wurden oder ein Fehler auftrat\n",
        "\n",
        "def submit_to_metamap_left_right_check(inputtext, tag, api_key):\n",
        "    # Ersetze Abkürzungen zuerst im gesamten Eingabetext\n",
        "    inputtext = replace_abbreviations(inputtext)\n",
        "\n",
        "    # Suche nach \"left\" oder \"right\" im bereits angepassten Text\n",
        "    direction_match = re.search(r\"\\b(left|right)\\b\", inputtext, flags=re.IGNORECASE)\n",
        "\n",
        "    if direction_match:\n",
        "        # Richtungsteil identifizieren (left/right)\n",
        "        direction_part = direction_match.group(0)\n",
        "        # Erzeuge den Rest des Textes, indem die identifizierte Richtung entfernt wird\n",
        "        rest_text = inputtext.replace(direction_part, '', 1).strip()\n",
        "\n",
        "        # Führe separate MetaMap-Anfragen für Richtungs- und Restteil durch\n",
        "        direction_codes = submit_to_metamap(direction_part, 'spco', api_key)\n",
        "        rest_codes = submit_to_metamap(rest_text, tag, api_key)\n",
        "\n",
        "        if not rest_codes:\n",
        "            return []\n",
        "\n",
        "        # Wenn direction_codes vorhanden sind, füge sie mit rest_codes zusammen\n",
        "        if direction_codes:\n",
        "            # Erstelle einen kombinierten String, wenn beide Listen Codes enthalten\n",
        "            combined_str = \" & \".join(direction_codes + rest_codes)\n",
        "            return [combined_str]\n",
        "        else:\n",
        "            # Keine direction_codes; gebe nur rest_codes zurück\n",
        "            return rest_codes\n",
        "    else:\n",
        "        # Wenn kein \"left\" oder \"right\" gefunden wurde, verarbeite den gesamten angepassten Text\n",
        "        return submit_to_metamap(inputtext, tag, api_key)\n",
        "\n",
        "\n",
        "def submit_to_metamap(inputtext, tag, api_key):\n",
        "    inst = Submission(email, api_key)\n",
        "    # Anpassen des Inputtexts\n",
        "    inputtext = replace_abbreviations(inputtext)\n",
        "    inst.init_mm_interactive(inputtext)\n",
        "\n",
        "    response = inst.submit()\n",
        "    response_content = response.text\n",
        "\n",
        "    filtered_info = []\n",
        "    backup_terms = []\n",
        "    term_printed = False  # Flag, um zu verfolgen, ob der Term bereits gedruckt wurde\n",
        "\n",
        "    for line in response_content.strip().split('\\n'):\n",
        "        parts = line.split('|')\n",
        "        try:\n",
        "          if len(parts) >= 6:\n",
        "              score, term, umls, current_tag = float(parts[2]), parts[3], parts[4], parts[5]\n",
        "              if score > 4:\n",
        "                  # Versuche zuerst, einen SNOMED CT Code zu finden, wenn der Tag passt\n",
        "                  if current_tag in tag:\n",
        "                      snomed_ct_codes = get_snomed_ct_codes_from_cui(umls, api_key, inputtext)\n",
        "                      if snomed_ct_codes:\n",
        "                          for code, name in snomed_ct_codes:\n",
        "                              #filtered_info.append(f\"Term: {term}, SNOMED CT Code: {code}, Name: {name}\")\n",
        "                              filtered_info.append(code)\n",
        "                              break  # Verlasse die Schleife nach dem ersten erfolgreichen Fund\n",
        "                      else:\n",
        "                          backup_terms.append((score, term, umls))  # Füge zu Backup hinzu, wenn kein Code gefunden wurde\n",
        "                  else:\n",
        "                      backup_terms.append((score, term, umls))  # Füge zu Backup hinzu, wenn der Tag nicht passt\n",
        "              elif not term_printed:\n",
        "                  print(inputtext)\n",
        "                  term_printed = True  # Setze das Flag, da der Term nun gedruckt wurde\n",
        "          else:\n",
        "            print(\"NICHT GENÜGEND SPALTEN IN DER ANTWORT\")\n",
        "            continue\n",
        "        except ValueError:\n",
        "            print(\"VALLLLLUEEEEEEEEEE EROORRRR\")\n",
        "            continue\n",
        "    # Wenn keine passenden SNOMED CT Codes mit dem spezifischen Tag gefunden wurden, versuche die Backup-Terms\n",
        "    if not filtered_info:\n",
        "        for score, term, umls in backup_terms:\n",
        "            snomed_ct_codes = get_snomed_ct_codes_from_cui(umls, api_key, inputtext)\n",
        "            if snomed_ct_codes:\n",
        "                for code, name in snomed_ct_codes:\n",
        "                    #filtered_info.append(f\"Term: {term}, SNOMED CT Code: {code}, Name: {name}\")\n",
        "                    filtered_info.append(code)\n",
        "                    break  # Verlasse die Schleife nach dem ersten erfolgreichen Fund\n",
        "            if filtered_info:  # Wenn wir erfolgreich einen SNOMED CT Code gefunden haben, brechen wir ab\n",
        "                break\n",
        "\n",
        "    if not filtered_info:  # Wenn immer noch keine Info gefunden wurde, füge einfach den besten Score-Term hinzu\n",
        "        if backup_terms:\n",
        "            score, term, umls = backup_terms[0]  # Nimm den ersten Term aus dem Backup\n",
        "            print(f\"Kein SNOMED CT Code gefunden für Term: {term}, UMLS: {umls}\")\n",
        "\n",
        "    #print(filtered_info)\n",
        "    return filtered_info\n",
        "\n",
        "# Diese Funktion bleibt unverändert\n",
        "def process_text_with_metamap(text, separator, tag,api_key):\n",
        "    processed_texts = []\n",
        "    for phrase in text.split(separator):\n",
        "        # Rufen Sie MetaMap für den Phrase auf und erhalten Sie eine Liste von Scores\n",
        "        metamap_response = submit_to_metamap_left_right_check(phrase.strip(), tag, api_key)\n",
        "        # Konvertieren Sie die Liste von Scores in einen String\n",
        "        scores_str = ', '.join(metamap_response)  # Erstellen eines Strings aus der Liste\n",
        "        # Fügen Sie den String zur Liste der verarbeiteten Texte hinzu\n",
        "        processed_texts.append(scores_str)\n",
        "    return separator.join(processed_texts)\n",
        "\n",
        "# Beispielhafte Anwendung:\n",
        "df = pd.read_csv('/content/drive/MyDrive/MIMIC-IV-ED/filtered_age_edstays_diagnosis_triage_medrecon_pyxis_firstrow.csv')\n",
        "\n",
        "df['icd_title'] = df['icd_title'].apply(lambda x: process_text_with_metamap(x, '|', [\"[dosy]\",\"[dsyn]\"], api_key) if pd.notnull(x) else x)\n",
        "#df['chiefcomplaint'] = df['chiefcomplaint'].apply(lambda x: process_text_with_metamap(x, ',', ['[sosy]'],api_key) if pd.notnull(x) else x)\n",
        "\n",
        "# Funktion zum Zählen der Codes in einer Zelle, getrennt durch \"|\"\n",
        "def zaehle_codes_in_zelle(zellenwert):\n",
        "    # Teile den String in eine Liste, basierend auf \"|\"\n",
        "    codes = str(zellenwert).split('|')\n",
        "    # Filtere leere Strings heraus und zähle die übrigen Einträge\n",
        "    return sum(len(code.strip()) > 0 for code in codes)\n",
        "\n",
        "# Wende die Funktion auf jede Zelle in der Spalte 'icd_code' und 'icd_title' an und summiere die Ergebnisse\n",
        "gesamtzahl_codes_icd_code = df['icd_code'].apply(zaehle_codes_in_zelle).sum()\n",
        "gesamtzahl_codes_icd_title = df['icd_title'].apply(zaehle_codes_in_zelle).sum()\n",
        "\n",
        "print(f\"Gesamtzahl der SNOMED CT Codes in 'icd_code': {gesamtzahl_codes_icd_code}\")\n",
        "print(f\"Gesamtzahl der SNOMED CT Title: {gesamtzahl_codes_icd_title}\")\n",
        "df.to_csv('/content/drive/MyDrive/MIMIC-IV-ED/output.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WnSd-oeAdzhW",
        "outputId": "e3cc79fa-c80d-48b4-87a0-24f09adcb3de"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-33b06d61cf8d>:10: DtypeWarning: Columns (6,7,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df_full = pd.read_csv(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kein SNOMED CT Code gefunden für Term: Unspecified viral hepatitis C without hepatic coma, UMLS: C1456263\n",
            "Kein SNOMED CT Code gefunden für Term: Unspecified viral hepatitis C without hepatic coma, UMLS: C1456263\n",
            "Kein SNOMED CT Code gefunden für Term: Unspecified viral hepatitis C without hepatic coma, UMLS: C1456263\n",
            "Kein SNOMED CT Code gefunden für Term: Unspecified dementia without behavioral disturbance, UMLS: C3161078\n",
            "Cellulitis/Abscess of the Mouth\n",
            "Local Superficial Swelling\n",
            "Cellulitis/Abscess of the Mouth\n",
            "Laceration with/o foreign body of oth part of head, subs encntr\n",
            "Fall from skateboard, subsequent encounter\n",
            "Kein SNOMED CT Code gefunden für Term: Fall from skateboard, UMLS: C0878747\n",
            "Fracture of tooth traumatic, init for clos fx\n",
            "Laceration with/o foreign body of oth part of head, init encntr\n",
            "Other fall from one level to another, initial encounter\n",
            "Oth fracture of head and neck of  femur, init\n",
            "Fall on same level, unspecified, initial encounter\n",
            "Other specified injuries of head, initial encounter\n",
            "Kein SNOMED CT Code gefunden für Term: Other specified injuries of head, UMLS: C0478216\n",
            "Laceration with/o Foreign Body of  eyelid and periocular area, init\n",
            "Striking against or struck by other objects, init encntr\n",
            "Kein SNOMED CT Code gefunden für Term: Contusion of abdominal wall, UMLS: C0160926\n",
            "Kein SNOMED CT Code gefunden für Term: Fall from snowboard, UMLS: C0878749\n",
            "ACTIVITIES INVOLVING SNOW ALPINE DOWNHILL SKIING, SNOW BOARDING, SLEDDING,TOBOGGANING AND SNOW TUBING\n",
            "Other specified noninfective gastroenteritis and colitis\n",
            "Essential primary hypertension\n",
            "upper quadrant pain\n",
            "Pneumonia, unspecified organism\n",
            "Flu due to unidentified influenza virus with oth resp manifest\n",
            "Essential primary hypertension\n",
            "Kein SNOMED CT Code gefunden für Term: Pain in limb, lower leg, UMLS: C0839480\n",
            "Kein SNOMED CT Code gefunden für Term: Pain in limb, lower leg, UMLS: C0839480\n",
            "Malignant Neoplasm of Bronchus/Lung, Not Otherwise Specified\n",
            "History of Bronchogenic Malignancy\n",
            "Kein SNOMED CT Code gefunden für Term: Sprain of unspecified ligament of ankle, UMLS: C2868862\n",
            "Fall on from unspecified stairs and steps, init encntr\n",
            "Pneumonia, unspecified organism\n",
            "ACUTE VENOUS EMBOLISM AND THROMBOSIS OF DEEP VESSELS OF DISTAL LOWER EXTREMITY\n",
            "Other specified anemias\n",
            "Kein SNOMED CT Code gefunden für Term: Other forms of dyspnea, UMLS: C2910383\n",
            "Long-term Use of Anticoagulants\n",
            "Coronary Artery Disease, Unspecified Vessel, Native or Graft\n",
            "Kein SNOMED CT Code gefunden für Term: Type 2 diabetes mellitus with diabetic chronic kidney disease, UMLS: C3250571\n",
            "Chronic kidney disease, stage 4 severe\n",
            "Other specified diseases of anus and rectum\n",
            "REMOVAL VASCULAR CATHETER\n",
            "ABDOMINAL PAIN RLQ\n",
            "Kein SNOMED CT Code gefunden für Term: Paresthesia of skin, UMLS: C0235046\n",
            "Contusion of  foot, initial encounter\n",
            "Ped on foot injured pick-up truck, pk-up/van in traf, init\n",
            "Kein SNOMED CT Code gefunden für Term: Other pulmonary embolism without acute cor pulmonale, UMLS: C2882222\n",
            "lower quadrant pain\n",
            "lower quadrant pain\n",
            "ACC-CUTTING INSTRUM NEC\n",
            "PERSONAL HISTORY OF CONTACT WITH AND SUSPECTED EXPOSURE TO POTENTIALLY HAZARDOUSBODY FLUIDS\n",
            "FALL FROM SIDEWALK CURB\n",
            "Long-term Use of Anticoagulants\n",
            "FX C2 VERTEBRA-CLOSED\n",
            "Kein SNOMED CT Code gefunden für Term: Accidental fall from commode, UMLS: C0375737\n",
            "Long-term Use of Anticoagulants\n",
            "Kein SNOMED CT Code gefunden für Term: Chronic Obstructive Pulmonary Disease EXACERBATION, UMLS: C0740848\n",
            "Kein SNOMED CT Code gefunden für Term: Chronic Obstructive Pulmonary Disease EXACERBATION, UMLS: C0740848\n",
            "OBSTRUCTIVE CHR. BRONCHITIS,WITH ACUTE EXACERBATION\n",
            "ABNORM ELECTROCARDIOGRAM\n",
            "Pneumonia, unspecified organism\n",
            "Kein SNOMED CT Code gefunden für Term: Chronic Obstructive Pulmonary Disease EXACERBATION, UMLS: C0740848\n",
            "Essential primary hypertension\n",
            "Kein SNOMED CT Code gefunden für Term: Chronic Obstructive Pulmonary Disease EXACERBATION, UMLS: C0740848\n",
            "Unspecified asthma with acute exacerbation\n",
            "Kein SNOMED CT Code gefunden für Term: Chronic Obstructive Pulmonary Disease EXACERBATION, UMLS: C0740848\n",
            "Kein SNOMED CT Code gefunden für Term: Chronic Obstructive Pulmonary Disease EXACERBATION, UMLS: C0740848\n",
            "Athscl heart disease of native coronary artery with/o ang pctrs\n",
            "Kein SNOMED CT Code gefunden für Term: Unspecified atrial fibrillation, UMLS: C3264374\n",
            "Kein SNOMED CT Code gefunden für Term: Chronic Obstructive Pulmonary Disease EXACERBATION, UMLS: C0740848\n",
            "Essential primary hypertension\n",
            "Kein SNOMED CT Code gefunden für Term: Chronic Obstructive Pulmonary Disease EXACERBATION, UMLS: C0740848\n",
            "Acute embolism and thrombosis of  subclavian vein\n",
            "Other specified soft tissue disorders\n",
            "Kein SNOMED CT Code gefunden für Term: vertigo/dizziness, UMLS: C0497293\n",
            "TOOTH BROKEN FRACTURED DUE TO TRAUMA, WITHOUT MENTION OF COMPLICATION\n",
            "STRUCK BY FALLING OBJECT\n",
            "CONCUSSION with/O COMA\n",
            "STRUCK BY OBJECT OR PERSON WITH OR WITHOUT FALL\n",
            "Renal and Ureteral Disorder, Not Otherwise Specified\n",
            "Myocardial Infarction, Not Otherwise Specified, Initial Episode of Care\n",
            "DIAB KETOACIDOSIS IDDM\n",
            "Kein SNOMED CT Code gefunden für Term: Type 1 diabetes mellitus with foot ulcer, UMLS: C2874062\n",
            "Non-pressure chronic ulcer oth prt  foot with unsp severity\n",
            "Essential primary hypertension\n",
            "Acute embolism and thrombosis of  femoral vein\n",
            "Kein SNOMED CT Code gefunden für Term: Pain in limb, lower leg, UMLS: C0839480\n",
            "PULM EMBOLISM/INFARCT\n",
            "lower quadrant pain\n",
            "Kein SNOMED CT Code gefunden für Term: Other specified disorders of brain, UMLS: C0477418\n",
            "SEMICOMA/STUPOR\n",
            "NONINF GASTROENTERIT NEC\n",
            "FX NECK OF FEMUR Not Otherwise Specified-CL\n",
            "ACUTE LARYNGITIS, WITHOUT MENTION OF OBSTRUCTION\n",
            "Laceration without foreign body of scalp, initial encounter\n",
            "Kein SNOMED CT Code gefunden für Term: Laceration without foreign body of scalp, UMLS: C2831009\n",
            "Fall on same level, unspecified, initial encounter\n",
            "Kein SNOMED CT Code gefunden für Term: Unspecified atrial fibrillation, UMLS: C3264374\n",
            "Oth pregnancy related conditions, second trimester\n",
            "Kein SNOMED CT Code gefunden für Term: 24 weeks gestation of pregnancy, UMLS: C3264102\n",
            "DIS OF GALLBLADDER NEC\n",
            "ABN BLOOD CHEMISTRY NEC\n",
            "Other specified abnormal uterine and vaginal bleeding\n",
            "Other specified postprocedural states\n",
            "Kein SNOMED CT Code gefunden für Term: Encounter due to presence of prosthetic heart valve, UMLS: C0478678\n",
            "ABDOMINAL PAIN RLQ\n",
            "Kein SNOMED CT Code gefunden für Term: Kidney Calculi, UMLS: C0022650\n",
            "Displacement of oth urinary devices and implants, init\n",
            "Oth surgical procedures cause abn react/compl, with/o misadvnt\n",
            "Kein SNOMED CT Code gefunden für Term: Etiology aspects, UMLS: C0015127\n",
            "Oth places as the place of occurrence of the external cause\n",
            "HEMORR COMPLIC PROCEDURE\n",
            "FOLLOW-UP EXAM NEC\n",
            "CHILLS WITHOUT FEVER\n",
            "Cannabis use, unspecified, uncomplicated\n",
            "ABDOMINAL PAIN LLQ\n",
            "ABDOMINAL PAIN RUQ\n",
            "Unsp disp fx of third cervical vertebra, init for clos fx\n",
            "Kein SNOMED CT Code gefunden für Term: TMSB4X wt Allele, UMLS: C4521346\n",
            "Fall on same level, unspecified, initial encounter\n",
            "OTHER OVEREXERTION AND STRENUOUS AND REPETIVE MOVEMENTS OR LOADS\n",
            "Kein SNOMED CT Code gefunden für Term: Ulcer of other part of lower limb, UMLS: C0878704\n",
            "Long-term Use of Anticoagulants\n",
            "Kein SNOMED CT Code gefunden für Term: Abnormal coagulation profile, UMLS: C0375576\n",
            "Kein SNOMED CT Code gefunden für Term: Encounter for issue of repeat prescription, UMLS: C0260845\n",
            "Essential primary hypertension\n",
            "Oth pregnancy related conditions, third trimester\n",
            "Other specified disorders of teeth and supporting structures\n",
            "Kein SNOMED CT Code gefunden für Term: 34 weeks gestation of pregnancy, UMLS: C3264113\n",
            "FX LOW RADIUS with ULNA-CL\n",
            "FALL FROM SIDEWALK CURB\n",
            "Laceration with/o Foreign Body of  idx fngr with/o damage to nail, init\n",
            "Contact with sharp glass, initial encounter\n",
            "Kein SNOMED CT Code gefunden für Term: occurrence of contact with sharp glass at unspecified place, UMLS: C0478944\n",
            "SHLDR/UPPER ARM INJ Not Otherwise Specified\n",
            "FALL ON STAIR/STEP NEC\n",
            "Kein SNOMED CT Code gefunden für Term: Stair (equipment), UMLS: C2825408\n",
            "Unsp superficial injury of unsp part of head, init encntr\n",
            "Fall on same level, unspecified, initial encounter\n",
            "Kein SNOMED CT Code gefunden für Term: Encounter due to vagabond status, UMLS: C0687129\n",
            "Kein SNOMED CT Code gefunden für Term: Unspecified viral hepatitis C without hepatic coma, UMLS: C1456263\n",
            "Oth psych disorder not due to a sub or known physiol cond\n",
            "Kein SNOMED CT Code gefunden für Term: HUTTERITE CEREBROOSTEONEPHRODYSPLASIA SYNDROME, UMLS: C1856054\n",
            "Kein SNOMED CT Code gefunden für Term: Type 2 diabetes mellitus with hyperglycemia, UMLS: C2874123\n",
            "Pain in  hand\n",
            "PATHOLOGIC FX VERTEBRAE\n",
            "NONTRAUM EXTRADURAL HEM\n",
            "LYMPHOMA NEC UNSPEC SITE\n",
            "FALL RESULTING IN STRIKING AGAINST OTHER OBJECT\n",
            "ACTIVITY INVOLVING AEROBIC AND STEP EXERCISE\n",
            "LYMPHOMA NEC UNSPEC SITE\n",
            "CAD NATIVE CORONARY VESSEL\n",
            "Laceration with/o Foreign Body of  idx fngr with/o damage to nail, init\n",
            "Contact with knife, initial encounter\n",
            "Kein SNOMED CT Code gefunden für Term: Contact with knife, UMLS: C2904192\n",
            "FX UPPER END TIBIA-CLOSE\n",
            "FX UPPER HUMERUS NEC-CL\n",
            "CEREBRAL ART OCCLUS with/INFARCT\n",
            "MUSCSKEL SYMPT LIMB NEC\n",
            "Kein SNOMED CT Code gefunden für Term: Other nonspecific abnormal finding of lung field, UMLS: C3161126\n",
            "Contusion of scalp, initial encounter\n",
            "Fall on from other stairs and steps, initial encounter\n",
            "Essential primary hypertension\n",
            "RECTAL & ANAL HEMORRHAGE\n",
            "MALIGNANT NEOPL RECTUM\n",
            "Kein SNOMED CT Code gefunden für Term: Abnormal coagulation profile, UMLS: C0375576\n",
            "Long-term Use of Anticoagulants\n",
            "Kein SNOMED CT Code gefunden für Term: Abnormal coagulation profile, UMLS: C0375576\n",
            "RECTAL & ANAL ULCER\n",
            "Exposure to other specified factors, initial encounter\n",
            "Kein SNOMED CT Code gefunden für Term: Exposure to other specified factors, UMLS: C0496512\n",
            "MYOCARDIAL INFARCTION Not Otherwise Specified, SUBSEQUENT EPISODE OF CARE\n",
            "CARDIAC DYSRHYTHMIAS NEC\n",
            "JOINT PAIN-/LEG\n",
            "ABCESS OF ANAL & RECTAL REGIONS\n",
            "Coronary Artery Disease, Unspecified Vessel, Native or Graft\n",
            "Traum subrac hem with/o loss of consciousness, init\n",
            "Fall on same level, unspecified, initial encounter\n",
            "Pneumonia, unspecified organism\n",
            "MV COLLISION Not Otherwise Specified-PASNGR\n",
            "POIS-BENZODIAZEPINE TRAN\n",
            "ACC POISN-BENZDIAZ TRANQ\n",
            "Cutaneous abscess of  lower limb\n",
            "Sepsis, unspecified organism\n",
            "Pneumonia, unspecified organism\n",
            "LOCAL SKIN INFECTION Not Otherwise Specified\n",
            "Essential primary hypertension\n",
            "CONTUSION OF FACE, SCALP, & NECK EXCEPT EYES\n",
            "STRUCK BY OBJECT OR PERSON WITH OR WITHOUT FALL\n",
            "JOINT PAIN-SHLDER\n",
            "ABN CARDIOVASC STUDY NEC\n",
            "Coronary Artery Disease, Unspecified Vessel, Native or Graft\n",
            "Infectious mononucleosis, unspecified without complication\n",
            "Kein SNOMED CT Code gefunden für Term: Convulsions, UMLS: C4048158\n",
            "Epilepsy, unsp, not intractable, without status epilepticus\n",
            "Athscl heart disease of native coronary artery with/o ang pctrs\n",
            "NONINFLAM DIS VAGINA NEC\n",
            "FEM GENITAL SYMPTOMS Not Otherwise Specified\n",
            "Acute embolism and thrombosis of  tibial vein\n",
            "FX LOW RADIUS with ULNA-CL\n",
            "FALL FROM OTHER SLIPPING,TRIPPING,STUMBLING\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-33b06d61cf8d>\u001b[0m in \u001b[0;36m<cell line: 232>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/MIMIC-IV-ED/filtered_age_edstays_diagnosis_triage_medrecon_pyxis_firstrow.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'icd_title'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'icd_title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprocess_text_with_metamap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'|'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"[dosy]\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"[dsyn]\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;31m#df['chiefcomplaint'] = df['chiefcomplaint'].apply(lambda x: process_text_with_metamap(x, ',', ['[sosy]'],api_key) if pd.notnull(x) else x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4769\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4770\u001b[0m         \"\"\"\n\u001b[0;32m-> 4771\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4773\u001b[0m     def _reduce(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;31m# self.f is Callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1123\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1175\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-33b06d61cf8d>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/MIMIC-IV-ED/filtered_age_edstays_diagnosis_triage_medrecon_pyxis_firstrow.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'icd_title'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'icd_title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprocess_text_with_metamap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'|'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"[dosy]\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"[dsyn]\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;31m#df['chiefcomplaint'] = df['chiefcomplaint'].apply(lambda x: process_text_with_metamap(x, ',', ['[sosy]'],api_key) if pd.notnull(x) else x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-33b06d61cf8d>\u001b[0m in \u001b[0;36mprocess_text_with_metamap\u001b[0;34m(text, separator, tag, api_key)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mphrase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseparator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;31m# Rufen Sie MetaMap für den Phrase auf und erhalten Sie eine Liste von Scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0mmetamap_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubmit_to_metamap_left_right_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m         \u001b[0;31m# Konvertieren Sie die Liste von Scores in einen String\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0mscores_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetamap_response\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Erstellen eines Strings aus der Liste\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-33b06d61cf8d>\u001b[0m in \u001b[0;36msubmit_to_metamap_left_right_check\u001b[0;34m(inputtext, tag, api_key)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;31m# Wenn kein \"left\" oder \"right\" gefunden wurde, verarbeite den gesamten angepassten Text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msubmit_to_metamap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-33b06d61cf8d>\u001b[0m in \u001b[0;36msubmit_to_metamap\u001b[0;34m(inputtext, tag, api_key)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0minst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_mm_interactive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0mresponse_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skr_web_api/__init__.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m302\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mnewurl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_redirect_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             response = s.post(newurl,\n\u001b[0m\u001b[1;32m    104\u001b[0m                               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                               \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    635\u001b[0m         \"\"\"\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mcontent\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONTENT_CHUNK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content_consumed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"stream\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m                     \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    817\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mChunkedEncodingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    622\u001b[0m         \"\"\"\n\u001b[1;32m    623\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_chunked_reads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_chunk_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_update_chunk_length\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb\";\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1303\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYb-7QTNXG8f"
      },
      "source": [
        "Abkürzungen in den Diagnosen sowie Symptomen erkennen und die richtige Formulierung finden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkT1zmURXA8N"
      },
      "outputs": [],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVoU6omrjC-i",
        "outputId": "0565854b-2c1f-47d1-827a-40a6d0a1266f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChatCompletionMessage(content='None', role='assistant', function_call=None, tool_calls=None)\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "# Once you add your API key below, make sure to not share it with anyone! The API key should remain private.\n",
        "OPENAI_API_KEY=\"your_key"\n",
        "client = OpenAI(api_key = OPENAI_API_KEY)\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant that recognizes medical abbreviations. First you check wether the term is an medical abbreviation or not. If it is not an abbreviation, your response is:None . If it is an abbreviation: You always return only the meaning of the abbreviation, nothing else. No explanation or anything else. Just one answer.\"},\n",
        "    {\"role\": \"user\", \"content\": \"ITIS C WITHOUT HEPATIC COMA|ASYMPTOMATIC HIV INFECTION\"}\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldMf5DwKfzcI"
      },
      "source": [
        "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"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgV-6HEfkhmX"
      },
      "source": [
        "Um Abkürzungen im Text zu finden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sde8ISKdo0MY",
        "outputId": "093be308-1059-4608-f6f9-da4f863aac1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'K': 'kitchen'}\n"
          ]
        }
      ],
      "source": [
        "def extract_acronym_from_text(original_text):\n",
        "    words = original_text.split()\n",
        "    acronym_dict = {}\n",
        "\n",
        "    for i in range(len(words)):\n",
        "        if i == 0 or (i > 0 and words[i - 1][-1] in \".!?\"):\n",
        "            word = words[i]\n",
        "            acronym = word[0].upper()\n",
        "            acronym_dict[acronym] = word\n",
        "\n",
        "    return acronym_dict\n",
        "print(extract_acronym_from_text(\"kitchen\"))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1TyTlIj2BrUwCQKY-UV-91IEIEEND-08R",
      "authorship_tag": "ABX9TyPvgmpKRHsc8Znd/krwVnnZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
